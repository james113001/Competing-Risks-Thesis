{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deepsurv\n",
      "  Using cached deepsurv-0.1.0.tar.gz (10 kB)\n",
      "Requirement already satisfied: theano in c:\\users\\james\\anaconda3\\lib\\site-packages (from deepsurv) (1.0.5)\n",
      "Collecting lasagne\n",
      "  Using cached Lasagne-0.1.tar.gz (125 kB)\n",
      "Collecting lifelines\n",
      "  Using cached lifelines-0.27.1-py3-none-any.whl (349 kB)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\james\\appdata\\roaming\\python\\python38\\site-packages (from theano->deepsurv) (1.22.3)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\james\\appdata\\roaming\\python\\python38\\site-packages (from theano->deepsurv) (1.16.0)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\james\\anaconda3\\lib\\site-packages (from theano->deepsurv) (1.9.0)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from lifelines->deepsurv) (1.4.2)\n",
      "Collecting autograd>=1.3\n",
      "  Using cached autograd-1.4-py3-none-any.whl (48 kB)\n",
      "Requirement already satisfied: matplotlib>=3.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from lifelines->deepsurv) (3.2.2)\n",
      "Collecting autograd-gamma>=0.3\n",
      "  Using cached autograd-gamma-0.5.0.tar.gz (4.0 kB)\n",
      "Collecting formulaic>=0.2.2\n",
      "  Using cached formulaic-0.3.4-py3-none-any.whl (68 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\james\\appdata\\roaming\\python\\python38\\site-packages (from pandas>=1.0.0->lifelines->deepsurv) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\james\\appdata\\roaming\\python\\python38\\site-packages (from pandas>=1.0.0->lifelines->deepsurv) (2.8.2)\n",
      "Requirement already satisfied: future>=0.15.2 in c:\\users\\james\\anaconda3\\lib\\site-packages (from autograd>=1.3->lifelines->deepsurv) (0.18.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\james\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->lifelines->deepsurv) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\james\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->lifelines->deepsurv) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\james\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->lifelines->deepsurv) (1.2.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting astor>=0.8\n",
      "  Using cached astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting interface-meta<2.0.0,>=1.2.0\n",
      "  Using cached interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: wrapt>=1.0 in c:\\users\\james\\anaconda3\\lib\\site-packages (from formulaic>=0.2.2->lifelines->deepsurv) (1.12.1)\n",
      "Building wheels for collected packages: deepsurv, lasagne, autograd-gamma\n",
      "  Building wheel for deepsurv (setup.py): started\n",
      "  Building wheel for deepsurv (setup.py): finished with status 'done'\n",
      "  Created wheel for deepsurv: filename=deepsurv-0.1.0-py3-none-any.whl size=11164 sha256=34d6ee01c8de5f1d051bda0960423165c266ace783120cb69e758748b8b635a4\n",
      "  Stored in directory: c:\\users\\james\\appdata\\local\\pip\\cache\\wheels\\8b\\35\\64\\cb4fa77f7de25e6133c42cc1749ecd28b82131fcc937ab37ee\n",
      "  Building wheel for lasagne (setup.py): started\n",
      "  Building wheel for lasagne (setup.py): finished with status 'done'\n",
      "  Created wheel for lasagne: filename=Lasagne-0.1-py3-none-any.whl size=79281 sha256=05073c2e9b54266837b5c7a81dcdbd552663feb7ae08ddf431bfb8a538b74999\n",
      "  Stored in directory: c:\\users\\james\\appdata\\local\\pip\\cache\\wheels\\25\\5b\\33\\563d410432dfba1865b036703f71b81d8565b1393846d2e611\n",
      "  Building wheel for autograd-gamma (setup.py): started\n",
      "  Building wheel for autograd-gamma (setup.py): finished with status 'done'\n",
      "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4034 sha256=726061a6986199fd2fa9b47ba7c659848d26ead93f4def9b7eb5e60c920ec845\n",
      "  Stored in directory: c:\\users\\james\\appdata\\local\\pip\\cache\\wheels\\16\\a2\\b6\\582cfdfbeeccd469504a01af3bb952fd9e7eccba40995eafea\n",
      "Successfully built deepsurv lasagne autograd-gamma\n",
      "Installing collected packages: lasagne, autograd, autograd-gamma, astor, interface-meta, formulaic, lifelines, deepsurv\n",
      "Successfully installed astor-0.8.1 autograd-1.4 autograd-gamma-0.5.0 deepsurv-0.1.0 formulaic-0.3.4 interface-meta-1.3.0 lasagne-0.1 lifelines-0.27.1\n"
     ]
    }
   ],
   "source": [
    "pip install deepsurv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'deepsurv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-391d526b64d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpycox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCoxPH\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdeepsurv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'deepsurv'"
     ]
    }
   ],
   "source": [
    "import pyarrow.feather as feather\n",
    "import torchtuples as tt\n",
    "import torch\n",
    "import numpy as np\n",
    "from pycox.models import CoxPH\n",
    "import deepsurv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmprsk = feather.read_feather('melanoma.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>status</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>year</th>\n",
       "      <th>thickness</th>\n",
       "      <th>ulcer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791209</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.384527</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.031755</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.406593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.071594</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.736264</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.161663</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>185.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.527473</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.691686</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>4492.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.274725</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.401848</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>4668.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.395604</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.347575</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>4688.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.417582</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.021940</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>4926.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.505495</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.124711</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>5565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.406593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.161663</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       time  status  sex       age      year  thickness  ulcer\n",
       "0      10.0     3.0  1.0  0.791209  0.666667   0.384527    1.0\n",
       "1      30.0     3.0  1.0  0.571429  0.400000   0.031755    0.0\n",
       "2      35.0     2.0  1.0  0.406593  1.000000   0.071594    0.0\n",
       "3      99.0     3.0  0.0  0.736264  0.400000   0.161663    0.0\n",
       "4     185.0     1.0  1.0  0.527473  0.200000   0.691686    1.0\n",
       "..      ...     ...  ...       ...       ...        ...    ...\n",
       "200  4492.0     2.0  1.0  0.274725  0.200000   0.401848    1.0\n",
       "201  4668.0     2.0  0.0  0.395604  0.200000   0.347575    0.0\n",
       "202  4688.0     2.0  0.0  0.417582  0.200000   0.021940    0.0\n",
       "203  4926.0     2.0  0.0  0.505495  0.133333   0.124711    0.0\n",
       "204  5565.0     2.0  0.0  0.406593  0.000000   0.161663    0.0\n",
       "\n",
       "[205 rows x 7 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmprsk ##scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = cmprsk.copy()\n",
    "df_test = df_train.sample(frac=0.2)\n",
    "df_train = df_train.drop(df_test.index)\n",
    "df_val = df_train.sample(frac=0.2)\n",
    "df_train = df_train.drop(df_val.index)\n",
    "\n",
    "\n",
    "x_train = df_train.astype('float32')\n",
    "x_val = df_val.astype('float32')\n",
    "x_test = df_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_target = lambda df: (df['time'].values, df['status'].values)\n",
    "y_train = get_target(x_train)\n",
    "y_val = get_target(x_val)\n",
    "durations_test, events_test = get_target(x_test)\n",
    "val = x_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input settings for DeepSurv\n",
    "\n",
    "n_nodes = 256\n",
    "in_features = x_train.shape[1]\n",
    "num_nodes = [n_nodes, n_nodes, n_nodes, n_nodes]\n",
    "out_features = 1\n",
    "batch_norm = True\n",
    "dropout = 0.4\n",
    "output_bias = False\n",
    "\n",
    "net_ds = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm, dropout, output_bias=output_bias)\n",
    "\n",
    "model_ = CoxPH(net_ds, tt.optim.Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "print(type(np.asarray(x_train)))\n",
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'deepsurv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-f1c68f893fa8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdeepsurv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msimsurvdata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'deepsurv' is not defined"
     ]
    }
   ],
   "source": [
    "deepsurv(data = simsurvdata(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Need all tensors to have same lenght.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-ac571f7e1639>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# finding the best learning rate from this model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mlrfinder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr_finder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#_ = lrfinder.plot()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mlrfinder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_best_lr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchtuples\\base.py\u001b[0m in \u001b[0;36mlr_finder\u001b[1;34m(self, input, target, batch_size, lr_min, lr_max, lr_range, n_steps, tolerance, callbacks, verbose, num_workers, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    337\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr_finder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m             self.fit(\n\u001b[0m\u001b[0;32m    340\u001b[0m                 \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pycox\\models\\cox.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, input, target, batch_size, epochs, callbacks, verbose, num_workers, shuffle, metrics, val_data, val_batch_size, **kwargs)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \"\"\"\n\u001b[0;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtuplefy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         return super().fit(input, target, batch_size, epochs, callbacks, verbose,\n\u001b[0m\u001b[0;32m     52\u001b[0m                            \u001b[0mnum_workers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_batch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m                            **kwargs)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchtuples\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, input, target, batch_size, epochs, callbacks, verbose, num_workers, shuffle, metrics, val_data, val_batch_size, **kwargs)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m         \u001b[0mdataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_dataloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m         \u001b[0mval_dataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mis_dl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mval_data\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchtuples\\base.py\u001b[0m in \u001b[0;36mmake_dataloader\u001b[1;34m(data, batch_size, shuffle, num_workers, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m             \u001b[0mDataLoaderBatch\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m \u001b[0mA\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mlike\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \"\"\"\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[0mdataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_dataloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchtuples\\tupletree.py\u001b[0m in \u001b[0;36mmake_dataloader\u001b[1;34m(data, batch_size, shuffle, num_workers, to_tensor, make_dataset, torch_ds_dl)\u001b[0m\n\u001b[0;32m    359\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtorch_ds_dl\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m         \u001b[0mDataLoader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 361\u001b[1;33m     \u001b[0mdataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    362\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context)\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# map-style\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m                     \u001b[0msampler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data_source, replacement, num_samples)\u001b[0m\n\u001b[0;32m     90\u001b[0m                              \"since a random permute will be performed.\")\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m             raise ValueError(\"num_samples should be a positive integer \"\n\u001b[0;32m     94\u001b[0m                              \"value, but got num_samples={}\".format(self.num_samples))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\sampler.py\u001b[0m in \u001b[0;36mnum_samples\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;31m# dataset size might change at runtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_samples\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchtuples\\data.py\u001b[0m in \u001b[0;36m__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mlens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlens\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Need all tensors to have same lenght.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Need all tensors to have same lenght."
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "# finding the best learning rate from this model\n",
    "lrfinder = model_.lr_finder(np.asarray(x_train), np.asarray(y_train), batch_size, tolerance=10)\n",
    "#_ = lrfinder.plot()\n",
    "lrfinder.get_best_lr()\n",
    "\n",
    "# setting the new number\n",
    "model_.optimizer.set_lr(0.001)\n",
    "model_.optimizer.param_groups[0]['lr']\n",
    "\n",
    "epochs = 512\n",
    "\n",
    "callbacks = [tt.callbacks.EarlyStopping()]\n",
    "verbose = True\n",
    "\n",
    "log = model_.fit(x_train, y_train, batch_size, epochs, callbacks, verbose,\n",
    "                val_data=val, val_batch_size=batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
